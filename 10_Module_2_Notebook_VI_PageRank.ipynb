{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zackives/upenn-cis5450-hw/blob/main/10_Module_2_Notebook_VI_PageRank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy6hpgnJY-Rp"
      },
      "source": [
        "# Ranking Graph Data\n",
        "\n",
        "Let's look at link analysis!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autograder setup"
      ],
      "metadata": {
        "id": "E7pUp7HAwQp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PLEASE ENSURE YOUR PENN-ID IS ENTERED CORRECTLY. IF NOT, THE AUTOGRADER WON'T KNOW WHO\n",
        "#TO ASSIGN POINTS TO YOU IN OUR BACKEND\n",
        "STUDENT_ID = 99999999 # YOUR PENN-ID GOES HERE AS AN INTEGER##PLEASE ENSURE YOUR PENN-ID IS ENTERED CORRECTLY. IF NOT, THE AUTOGRADER WON'T KNOW WHO"
      ],
      "metadata": {
        "id": "WGM-vv4owbBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile notebook-config.yaml\n",
        "\n",
        "grader_api_url: 'https://23whrwph9h.execute-api.us-east-1.amazonaws.com/default/Grader23'\n",
        "grader_api_key: 'flfkE736fA6Z8GxMDJe2q8Kfk8UDqjsG3GVqOFOa'"
      ],
      "metadata": {
        "id": "OxKJ5J_awSOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%set_env HW_ID=cis5450_25f_HW9"
      ],
      "metadata": {
        "id": "RfX8o5jjwe0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install penngrader-client"
      ],
      "metadata": {
        "id": "S3n0LqhuwW2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from penngrader.grader import *\n",
        "\n",
        "grader = PennGrader('notebook-config.yaml', os.environ['HW_ID'], STUDENT_ID, STUDENT_ID)"
      ],
      "metadata": {
        "id": "dEHXUnRqwcP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load LinkedIn Graph"
      ],
      "metadata": {
        "id": "FdmHQUsjAM5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/penn-cis5450/linkedin_anon.jsonl"
      ],
      "metadata": {
        "id": "-ngX1IlrAUyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "people_df = pd.read_json('linkedin_anon.jsonl', lines=True, nrows=5000)"
      ],
      "metadata": {
        "id": "Uvi9p5pAAgvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the index with a numeric one\n",
        "people_df['_id'] = people_df.index"
      ],
      "metadata": {
        "id": "82NQeWBFA7bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nested_dict(rel, name):\n",
        "  # This evaluates the string that describes the dictionary, as a dictionary\n",
        "  # definition\n",
        "  ret = rel.copy()\n",
        "  # ret[name] = rel[name].map(lambda x: ast.literal_eval(x) if len(x) else np.NaN)\n",
        "  ret = ret.dropna()\n",
        "  # This joins rows on the index\n",
        "  return ret.drop(columns=name).join(pd.DataFrame(ret[name].tolist()))\n",
        "\n",
        "def get_nested_list(rel, name):\n",
        "  ret = rel.copy()\n",
        "  ret = ret.dropna().explode(name).dropna()\n",
        "  ret = ret.join(pd.DataFrame(ret[name].tolist())).drop(columns=name).drop_duplicates()\n",
        "  return ret.rename(columns={0: name})\n",
        "\n",
        "def get_nested_list_dict(rel, name):\n",
        "  ret = rel.copy()\n",
        "\n",
        "  ret = ret.dropna().explode(name)\n",
        "\n",
        "  exploded_pairs = pd.DataFrame(ret.apply(lambda x: {'_id': x['_id']} | x[name] if isinstance(x[name], dict) else {'_id': x['_id']}, axis=1).tolist())\n",
        "\n",
        "  return ret.merge(exploded_pairs, on='_id').drop(columns=name)\n",
        "\n",
        "names_df = get_nested_dict(people_df[['_id','name']], 'name')\n",
        "\n",
        "experience_df = get_nested_list_dict(people_df[['_id','experience']], 'experience')\n",
        "\n",
        "people_df = people_df.drop(columns=['name','education','group','skills','experience','honors','events','specilities','interests']).merge(names_df,on='_id')"
      ],
      "metadata": {
        "id": "udyz2rOyAmj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experience_df"
      ],
      "metadata": {
        "id": "PcTnq8otBFTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's make some changes to convert people IDs to integers, and create IDs for the organizations they've worked for."
      ],
      "metadata": {
        "id": "J6mwyMpdCfBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "organizations_df = experience_df['org'].drop_duplicates()\n",
        "\n",
        "org_id_start = len(people_df)\n",
        "\n",
        "organizations_df = organizations_df.reset_index().rename(columns={'org':'name'})\n",
        "organizations_df['index'] = organizations_df['index'].apply(lambda x: x + org_id_start)\n",
        "organizations_df"
      ],
      "metadata": {
        "id": "XHAUgjNCBLPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a relation of edges now."
      ],
      "metadata": {
        "id": "-834SJKGCkKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edges_df = experience_df[['_id','org']].merge(organizations_df,left_on='org',right_on='name').\\\n",
        "  drop(columns=['name','org']).rename(columns={'_id': 'from', 'index': 'to'})\n",
        "\n",
        "edges_reversed_df = edges_df.rename(columns={'from': 'to', 'to': 'from'})\n",
        "\n",
        "edges_df = pd.concat([edges_df, edges_reversed_df]).drop_duplicates()\n",
        "edges_df"
      ],
      "metadata": {
        "id": "-uvVtyAqB0MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(edges_df['from'])"
      ],
      "metadata": {
        "id": "knXiLySsGf1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(edges_df['to'])"
      ],
      "metadata": {
        "id": "TSChGS1ZGjBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For PageRank we need to scale the weight transfer by the number of out-edges. To do that let's count the number of out-links for each node.  This gets all of the edges, except for nodes that have no connections!"
      ],
      "metadata": {
        "id": "1Xzn-NKnD35P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outlinks_df = edges_df.groupby('from').size().to_frame('outlinks')\n",
        "display(outlinks_df)"
      ],
      "metadata": {
        "id": "1Vivr7T6DfvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the organizations and people without edges.  We'll use this result but it won't actually affect the computation...  Nonetheless it's good to understand how to compute it.  You'll see that there *are* people who have no edges."
      ],
      "metadata": {
        "id": "PDBKtmQXbamn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is equivalent to a \"left antijoin\": organizations where there is a left_only result, i.e., no match on the right\n",
        "sinks_df = organizations_df.merge(edges_df, how='left', left_on='index', right_on='from', indicator=True).query(\"_merge == 'left_only'\")[['index']].rename(columns={'index': 'from'})\n",
        "# Similar to above but in reverse.\n",
        "sinks_df_2 = people_df.merge(edges_df, how='left', left_on='_id', right_on='from', indicator=True).query(\"_merge == 'left_only'\")[['_id']].rename(columns={'_id': 'from'})\n",
        "sinks_df = pd.concat([sinks_df, sinks_df_2])\n",
        "sinks_df['outlinks'] = 0\n",
        "sinks_df = sinks_df.set_index('from')\n",
        "sinks_df"
      ],
      "metadata": {
        "id": "uGhIwlxaaCbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outlinks_df = pd.concat([outlinks_df, sinks_df])\n",
        "outlinks_df"
      ],
      "metadata": {
        "id": "tSh9VN9qacR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see the whole process.  We'll join the edges with their weight transfers. Note that this means nodes with no weight transfer won't be considered."
      ],
      "metadata": {
        "id": "3KROiw3RECu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight_transfer_df = edges_df.merge(outlinks_df, left_on='from', right_index=True)\n",
        "weight_transfer_df['weight'] = weight_transfer_df['outlinks'].apply(lambda x: 1 / x if x > 0 else 0)\n",
        "weight_transfer_df"
      ],
      "metadata": {
        "id": "5CFd3odTDoCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_transfer_df = weight_transfer_df.drop(columns=['outlinks']).dropna()\n",
        "weight_transfer_df"
      ],
      "metadata": {
        "id": "Q3IL9DL4EF9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert to a Matrix\n",
        "\n",
        "Now let's convert to a matrix..."
      ],
      "metadata": {
        "id": "OL5VLexlDBcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(weight_transfer_df)\n"
      ],
      "metadata": {
        "id": "a4Jh47TzE9Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_matrix(node_df, weight_transfer_df):\n",
        "  \"\"\"\n",
        "  node_df: set of nodes in a dataframe, with unique node index values\n",
        "  weight_transfer_df: set of edges in a dataframe, with weights\n",
        "  \"\"\"\n",
        "  max_id = max(organizations_df['index'])\n",
        "\n",
        "  weight_transfer_mat = np.zeros((max_id+1, max_id+1))\n",
        "\n",
        "  for i, row in weight_transfer_df.iterrows():\n",
        "    weight_transfer_mat[int(row['to']), int(row['from'])] = row['weight']\n",
        "\n",
        "  return weight_transfer_mat\n",
        "\n",
        "def matrix_pagerank(weight_transfer_mat, max_iter=100, alpha=0.85):\n",
        "  \"\"\"\n",
        "  weight_transfer_mat: matrix of weights\n",
        "  alpha: damping factor\n",
        "  max_iter: maximum number of iterations\n",
        "  \"\"\"\n",
        "  beta = 1 - alpha\n",
        "  n = weight_transfer_mat.shape[0]\n",
        "  # Initialize PageRank to 1/n\n",
        "  pr = np.ones(weight_transfer_mat.shape[0]) / weight_transfer_mat.shape[0]\n",
        "\n",
        "  for i in range(max_iter):\n",
        "    pr = beta * (weight_transfer_mat @ pr) + alpha / weight_transfer_mat.shape[0]\n",
        "\n",
        "  return pr"
      ],
      "metadata": {
        "id": "W7cxBW5DDOK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_transfer_mat = compute_matrix(organizations_df, weight_transfer_df)\n",
        "\n",
        "pr = matrix_pagerank(weight_transfer_mat, 5)\n",
        "pr"
      ],
      "metadata": {
        "id": "tYN1JzL1eSq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "Suppose that we have people who are only connected to a single organization, organizations with a single person. Given that we are treating edges as bidirectional: such nodes, even though they act very much like a *sink*, technically have one out-edge (back to whoever connects to them).\n",
        "\n",
        "Can you remove all *self-loops* and *sinks* from the graph, and recompute the matrices?"
      ],
      "metadata": {
        "id": "sZCvjQKHtT7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO:\n",
        "edges_df_2 = # TODO\n",
        "\n",
        "len(edges_df_2)"
      ],
      "metadata": {
        "id": "kigp4IpkHPWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outlinks_df_2 = # TODO\n",
        "\n",
        "weight_transfer_df_2 = # TODO\n",
        "weight_transfer_df_2"
      ],
      "metadata": {
        "id": "nZVq6XQUdV9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_transfer_mat_2 = compute_matrix(organizations_df, weight_transfer_df_2)\n",
        "\n",
        "pr2 = matrix_pagerank(weight_transfer_mat_2, 5)\n",
        "pr2"
      ],
      "metadata": {
        "id": "mAH0A98Hfzl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grader.grade('pagerank', pr2[0:1000])"
      ],
      "metadata": {
        "id": "MICXh_o6HezG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CxSt80L-IeRB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
