{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zackives/upenn-cis5450-hw/blob/main/11_Module_3_Part_1_Data_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6KEo6mHQuTq"
      },
      "source": [
        "# Lecture Notebook: Information Visualization\n",
        "\n",
        "\n",
        "This notebook covers several things:\n",
        "\n",
        "1. The basics of plotting Pandas dataframes using matplotlib.\n",
        "2. Some rules of thumb about bar vs line charts, axes, normalization, and whether to interpolate.\n",
        "3. Basics of ggplot on Python\n",
        "4. Seaborn and visualization of statistical data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autograder setup!\n"
      ],
      "metadata": {
        "id": "d9hfbxMkisqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PLEASE ENSURE YOUR PENN-ID IS ENTERED CORRECTLY. IF NOT, THE AUTOGRADER WON'T KNOW WHO\n",
        "#TO ASSIGN POINTS TO YOU IN OUR BACKEND\n",
        "STUDENT_ID = 99999999 # YOUR PENN-ID GOES HERE AS AN INTEGER##PLEASE ENSURE YOUR PENN-ID IS ENTERED CORRECTLY. IF NOT, THE AUTOGRADER WON'T KNOW WHO"
      ],
      "metadata": {
        "id": "Qfknlkq4ivG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile notebook-config.yaml\n",
        "\n",
        "grader_api_url: 'https://23whrwph9h.execute-api.us-east-1.amazonaws.com/default/Grader23'\n",
        "grader_api_key: 'flfkE736fA6Z8GxMDJe2q8Kfk8UDqjsG3GVqOFOa'"
      ],
      "metadata": {
        "id": "aMFLCrLAiwR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%set_env HW_ID=cis5450_25f_HW9"
      ],
      "metadata": {
        "id": "05bmrWa4ix5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install penngrader-client"
      ],
      "metadata": {
        "id": "krUHIp7dizi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from penngrader.grader import *\n",
        "\n",
        "grader = PennGrader('notebook-config.yaml', os.environ['HW_ID'], STUDENT_ID, STUDENT_ID)"
      ],
      "metadata": {
        "id": "P2FrrLLti1xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Visualization Libraries"
      ],
      "metadata": {
        "id": "FArS_3E2i4Z_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdHzd642QXM5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT00LjLEflSC"
      },
      "source": [
        "# Loading familiar data into Pandas\n",
        "\n",
        "We'll use the CEOs dataset from Wikipedia as an example to compare two different sub-populations: those CEOs who are actually **founders**, and those who are simply \"**regular CEOs**\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "def import_html(url: str):\n",
        "  # Now let's read an HTML table!\n",
        "  headers = {\n",
        "      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "  }\n",
        "\n",
        "  return requests.get(url, headers=headers).text\n"
      ],
      "metadata": {
        "id": "XWt-1r8XVaGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIoZ4qJ6QrXG"
      },
      "source": [
        "# Read the Wikipedia HTML table containing information about CEOs!\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_chief_executive_officers#List_of_CEOs'\n",
        "company_ceos_df = pd.read_html(StringIO(import_html(url)))[1]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "company_ceos_df"
      ],
      "metadata": {
        "id": "ruG8eLP0V6kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "company_ceos_df.dropna(subset = ['Since'], inplace=True)\n",
        "# Clean the references out of the Since field and the Title field...\n",
        "company_ceos_df['Since'] = company_ceos_df['Since'].apply(lambda x: int(x.split(' ')[-1]) if not pd.isna(x) and ' ' in x else x)\n",
        "company_ceos_df['Since'] = company_ceos_df['Since'].apply(lambda x: int(x.split('[')[0].strip()) if (not pd.isna(x)) and isinstance(x, str) and '[' in x else int(x))\n",
        "company_ceos_df['Title'] = company_ceos_df['Title'].apply(lambda x: x.split('[')[0].strip() if '[' in x else x)\n",
        "\n",
        "for i in range(0,len(company_ceos_df)):\n",
        "  print(company_ceos_df.iloc[i]['Executive'] + ': ' + str(company_ceos_df.iloc[i]['Since']))\n",
        "# Show the output\n",
        "company_ceos_df.info()"
      ],
      "metadata": {
        "id": "8XvzVveZV4-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy8U5T75Wzv1"
      },
      "source": [
        "Now that we have the data, let's split into two dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh5dOJUpQ-dl"
      },
      "source": [
        "# Split the founders\n",
        "founders_df = company_ceos_df[company_ceos_df['Title'].apply(lambda s: True if 'founder' in s.lower() else False)]\n",
        "\n",
        "# This is a set difference: we keep only items that are duplicated\n",
        "regular_ceos_df = pd.concat([company_ceos_df, founders_df]).drop_duplicates(keep=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyLqqeafeMIC"
      },
      "source": [
        "# For inspection: who are non-founders?\n",
        "regular_ceos_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quByX_1Mfd9L"
      },
      "source": [
        "# For inspection: who are non-founders?\n",
        "\n",
        "founders_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHbb8EwFiDZE"
      },
      "source": [
        "## Plotting our first graph\n",
        "\n",
        "OK, so we'll do our first plot.  We want to see company vs CEO start year, for CEOs who are also founders.  This is a *bar chart* since companies are categorical rather than continuous-valued."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9dl-lZWfgaT"
      },
      "source": [
        "founders_df.plot(kind='bar', x='Company', y='Since', color='gray')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d_9v7Bhgo4M"
      },
      "source": [
        "This looks pretty ridiculous, because the assumption is that dates start at 0, and that we are measuring dates!  \n",
        "\n",
        "Could we change the graphed value to that conceptually makes more sense, e.g., maybe we should look at **how long** people have been CEOs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrp2yL_zgPx_"
      },
      "source": [
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "founders_df['Years'] = founders_df['Since'].apply(lambda x: now.year - x)\n",
        "\n",
        "fig = founders_df.plot(kind='bar', x='Company', y='Years')\n",
        "\n",
        "\n",
        "# Based on \"domain expertise\", we will assume no one should be CEO for more\n",
        "# than ~70 years -- if they started at 20, they would be 90...\n",
        "fig.set_ylim([0, 70])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_oD1C4MjgUE"
      },
      "source": [
        "## Plotting for comparison\n",
        "\n",
        "Let's look at how many folks founded companies in each year, comparing founding CEOs vs \"regular\" CEOs...\n",
        "\n",
        "Here, year can be considered a continuous-valued parameter (although note that we are actually quantizing it to integer values, so fractional years aren't really useful here)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECgIf3jlhWJL"
      },
      "source": [
        "\n",
        "# gca stands for 'get current axis'\n",
        "ax = plt.gca()\n",
        "\n",
        "# This will create counts for how many founders started in each year\n",
        "founders_by_year = founders_df.groupby(['Since']).count()\n",
        "\n",
        "founder = founders_by_year.plot(kind='line',y='Company',ax=ax, label='Founding CEOs')\n",
        "regular_ceos_by_year = regular_ceos_df.groupby(['Since']).count()\n",
        "\n",
        "regular = regular_ceos_by_year.plot(kind='line',y='Company', color='red', ax=ax, \\\n",
        "                                    label='Other CEOs')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53Ekvt4NKem-"
      },
      "source": [
        "If we look closely at this graph, we'll note there seems to be one founding CEO every year. Could that be?  Maybe we should look more closely!!!\n",
        "\n",
        "We'll re-plot, putting a marker at each point.  And perhaps we can even remove the line from the \"founding CEO\" plot, just looking at the markers..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-89uCsBijwN"
      },
      "source": [
        "\n",
        "# gca stands for 'get current axis' and if we share the x-axis,\n",
        "# we will be able to plot multiple items against it\n",
        "ax = plt.gca()\n",
        "\n",
        "# This will create counts for how many founders started in each year\n",
        "founders_by_year = founders_df.groupby(['Since']).count()\n",
        "\n",
        "founder = founders_by_year.plot(kind='line',y='Company',ax=ax, label='Founding CEOs',\n",
        "                                marker='x', linewidth=0)\n",
        "regular_ceos_by_year = regular_ceos_df.groupby(['Since']).count()\n",
        "\n",
        "regular = regular_ceos_by_year.plot(kind='line',y='Company', color='red', ax=ax,\n",
        "                                    label='Other CEOs', marker='+')\n",
        "\n",
        "plt.xlabel('Year CEO started', fontsize = 16)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGDbwEEZKri3"
      },
      "source": [
        "Much clearer -- in fact the blue x's show that founding CEOs are not that common!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKLqEO8cKzqt"
      },
      "source": [
        "## Plotting and Thinking about Scale\n",
        "\n",
        "Let's try another plot, here comparing three items..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcfi55PMbD-v"
      },
      "source": [
        "graph_df = pd.DataFrame([{'scale': 100, 'value': 800}, {'scale': 200, 'value': 1200}, {'scale': 500, 'value': 2400}])\n",
        "\n",
        "graph_df.plot(kind='bar', x='scale', y='value', label='Execution time')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uxzMe6HK6sk"
      },
      "source": [
        "This plot is perfectly fine, but note that the x-axis actually contains **numeric** items, which might be continuous-valued.  Moreover, there is neither a log-scale nor a linear-scale progression along the axis -- so while our eyes see something that looks non-linear, in fact we can plot this as a line chart and see what's really happening..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmVjYmr7c0TA"
      },
      "source": [
        "graph_df.plot(kind='line', x='scale', y='value', label='Execution time', marker='o')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXowytb7LKEn"
      },
      "source": [
        "## Plotting and Normalization\n",
        "\n",
        "Now let's look at data and scaling, where perhaps we are looking at phenomena that are quite different.  A common situation is to measure the running time of three computations, using some baseline computation and comparing it with some alternate computation.  We can plot this using bar charts as we see below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVscywNTc_Av"
      },
      "source": [
        "# Suppose we are counting, for three computations, two different components, the\n",
        "# baseline computation and the alternative.\n",
        "\n",
        "# These are the \"baseline\" numbers for some computation\n",
        "baseline_df = pd.DataFrame([{'comp': 1, 'value': 800}, {'comp': 2, 'value': 5}, {'comp': 3, 'value': 2400}])\n",
        "# These are alternative computations\n",
        "alternative_df = pd.DataFrame([{'comp': 1, 'value': 720}, {'comp': 2, 'value': 3}, {'comp': 3, 'value': 2100}])\n",
        "\n",
        "# We want to plot side-by-side\n",
        "combined_df = baseline_df.rename(columns={'value': 'baseline'})\n",
        "combined_df['alternative'] = alternative_df['value']\n",
        "\n",
        "fig = combined_df.plot.bar(x='comp')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjMnt61ALYk-"
      },
      "source": [
        "Wow, we can't see computation #2 at all!  Given that each plot is very different, we may want to normalize each..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0ujPjTCiliP"
      },
      "source": [
        "rescaled_df = combined_df.copy()\n",
        "rescaled_df['alternative'] = combined_df.apply(lambda r: r['alternative'] / r['baseline'], axis=1)\n",
        "rescaled_df['baseline'] = combined_df.apply(lambda r: 1.0, axis=1)\n",
        "\n",
        "fig = rescaled_df.plot(kind='bar', x='comp')\n",
        "fig.set_title('Normalized Performance')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNaAb1GiLe8W"
      },
      "source": [
        "Note that an \"honest\" presentation of the data will emphasize that these are normalized, and that the relative running times are quite different.  In fact, sometimes people will put a caption above each bar showing the actual timings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uotl_BTdOLbF"
      },
      "source": [
        "# Visualization of Statistical Data with Seaborn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQvzJJo5OrcA"
      },
      "source": [
        "!pip install seaborn\n",
        "\n",
        "import seaborn as sb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmsEaI8qJSHN"
      },
      "source": [
        "# Some simple data, random points around a line\n",
        "points = 150\n",
        "slope = 0.3\n",
        "\n",
        "x = np.array(range(points))\n",
        "# We'll plot these\n",
        "y = np.random.randn(points) * 5 + x * slope\n",
        "# Choose a random integer, set z to True if it's positive, else set z to False\n",
        "z = map(lambda x: x >= 0, np.random.randn(points))\n",
        "\n",
        "sample_df = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
        "\n",
        "sample_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B81PAc5lO6iq"
      },
      "source": [
        "# Do a scatter plot, with height 4, shading the points based on whether z is True\n",
        "sb.lmplot(data=sample_df, x='x', y='y', height=4, aspect=1.5, fit_reg=False, hue=\"z\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TL0v491PIs8"
      },
      "source": [
        "# Do a scatter plot, with height 4, shading the points based on whether z is True\n",
        "sb.lmplot(data=sample_df, x='x', y='y', height=4, aspect=1.5, fit_reg=True, hue=\"z\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jrHsmGiS9--"
      },
      "source": [
        "# Sample dataset with people + tips\n",
        "tips_dataset = sb.load_dataset('tips')\n",
        "\n",
        "tips_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VH5IkxuTS-k"
      },
      "source": [
        "# Sample dataset with people + tips\n",
        "tips_dataset = sb.load_dataset('tips')\n",
        "\n",
        "# The question: how do people tip on different days of the week?\n",
        "tips_dataset['tip_pct'] = tips_dataset.apply(lambda r: r['tip'] / r['total_bill'], axis=1)\n",
        "\n",
        "# We will create a different graph for each value of 'time' (lunch vs dinner)\n",
        "g = sb.FacetGrid(tips_dataset, col='time', hue='day',\n",
        "                 height=4, aspect=1)\n",
        "\n",
        "# Within each graph, plot total bill vs tip\n",
        "g.map(plt.scatter, 'total_bill', 'tip_pct')\n",
        "g.add_legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S5PgRqxeAYK"
      },
      "source": [
        "# We will create a different graph for each value of 'time' (lunch vs dinner)\n",
        "g = sb.FacetGrid(tips_dataset, col='time', hue='day',\n",
        "                 height=4, aspect=1)\n",
        "\n",
        "# Within each graph, plot total bill vs tip\n",
        "g.map(plt.scatter, 'total_bill', 'size')\n",
        "g.add_legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdlCZlwtTtdh"
      },
      "source": [
        "# Let's look at how different factors are influenced by the size\n",
        "# of the party\n",
        "sb.pairplot(data=tips_dataset,kind='scatter', hue='size')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohOWqZ2FVdZJ"
      },
      "source": [
        "# Create histogram bins of size 5\n",
        "bins = np.arange(tips_dataset.total_bill.min(), tips_dataset.total_bill.max(), 5)\n",
        "\n",
        "# Cut the bins, and group by size\n",
        "by_bill_binned = tips_dataset.groupby([pd.cut(tips_dataset.total_bill, bins, precision=0),\n",
        "                                       'size']).size().unstack().fillna(0)\n",
        "\n",
        "by_bill_binned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlo6f_kQYpgj"
      },
      "source": [
        "sb.set(font_scale=1.0)\n",
        "\n",
        "sb.heatmap(by_bill_binned[by_bill_binned.sum(axis=1) > 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS7g8BgEY5_C"
      },
      "source": [
        "sb.boxplot(x=tips_dataset.time, y=tips_dataset.total_bill)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDWqYTaRas9-"
      },
      "source": [
        "tips_dataset.total_bill.sort_values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "### Are we confident lunch and dinner have different price distributions?\n",
        "\n",
        "We talked about the *t-test* as a way of comparing whether two distributions have different means.  Let us compare lunch vs. dinner `total_bill` and see what the *p-value* is, with regards to refuting the null hypothesis (establishing the distibutions are different).  Use the standard measure of *alpha* (the p-value threshold) for scientific results.\n",
        "\n"
      ],
      "metadata": {
        "id": "NfQjKg8EXzCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Separate the total bills for lunch and dinner\n",
        "lunch_bills = tips_dataset[tips_dataset['time'] == 'Lunch']['total_bill']\n",
        "dinner_bills = tips_dataset[tips_dataset['time'] == 'Dinner']['total_bill']\n",
        "\n",
        "# Perform the independent samples t-test, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n",
        "# TODO\n",
        "t_statistic, p_value = # Something\n",
        "\n",
        "# Print the results\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpret the results\n",
        "alpha = # TODO\n",
        "if p_value < alpha:\n",
        "  grader.grade(test_case_id='lunch', answer=True)\n",
        "else:\n",
        "  grader.grade(test_case_id='lunch', answer=False)\n"
      ],
      "metadata": {
        "id": "5Ks-btkkUtg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PeicqLhBYfpJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}